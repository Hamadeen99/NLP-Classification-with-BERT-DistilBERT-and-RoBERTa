# NLP-Classification-with-BERT-DistilBERT-and-RoBERTa-
This project explores the use of pretrained transformer models for NLP classification tasks, specifically on the emotion and DBpedia datasets . The models used include: - **BERT (Bidirectional Encoder Representations from Transformers) - DistilBERT (a distilled version of BERT)- RoBERTa (Robustly Optimized BERT)
